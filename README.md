# Semantic-Analysis-of-Financial-News-via-RAG

# Step 1 â€” Data Collection & Preprocessing

## ğŸ¯ Objective
Prepare the text corpus for the RAG system by collecting, cleaning, and structuring financial news and SEC filings.

---

## ğŸ§© Steps Completed
1. Installed dependencies: `pandas`, `langchain`, `sentence-transformers`, `faiss-cpu`.
2. Collected financial news from **Yahoo Finance RSS** feeds.
3. Loaded and simulated **SEC filings** for major tech companies.
4. Cleaned and merged multiple text sources into a unified corpus.
5. Saved the preprocessed data as `financial_documents.csv`.

---

## ğŸ“ Output Files
- `financial_documents.csv` â€” Unified dataset combining financial news and filings.

---

# Step 2 â€” Semantic Embedding & Vector Indexing (FAISS)

## ğŸ¯ Objective
Convert financial text data into semantic embeddings using **Sentence Transformers**, and store them in a **FAISS** index for similarity-based retrieval.

---

## ğŸ§© Steps Completed
1. Loaded the preprocessed dataset from Day 1 (`financial_documents.csv`).
2. Used `sentence-transformers/all-MiniLM-L6-v2` to embed each text entry.
3. Initialized a **FAISS** index for storing embeddings and enabling fast vector search.
4. Validated the setup by testing retrieval with example financial queries.
5. Saved the FAISS index and data mappings for downstream RAG operations.

---

## ğŸ“Š Example Query
**Query:** â€œApple quarterly earnings reportâ€

**Results:**
1. *Apple reports Q2 revenue of $117Bâ€¦*  
2. *AAPL stock sees uptick after earnings releaseâ€¦*  
3. *Appleâ€™s service revenue drives growth.*

---

## ğŸ“ Output Files
- `financial_news_index.faiss` â€” FAISS vector index storing all embeddings  
- `financial_documents_with_embeddings.csv` â€” Documents with metadata  

---

## ğŸ§  Concepts Learned
- Semantic embeddings with Sentence Transformers  
- Vector-based similarity search using FAISS  
- Building a scalable base for RAG systems  

---

# Step 3 â€” Retrieval-Augmented Generation (RAG) Pipeline

## ğŸ¯ Objective
Build a **RAG system** that combines **semantic retrieval** (FAISS) with a **language model** to answer queries using real financial documents.

---

## ğŸ§© Steps Completed
1. Loaded FAISS index and preprocessed financial document metadata.
2. Built a custom **FAISS retriever** class:
   - Retrieves the top-k semantically similar documents for a query.
3. Integrated a **local LLM** (`google/flan-t5-small`) for summarization and question answering.
4. Tested the RAG pipeline with example queries:
   - Query: â€œApple quarterly revenue performanceâ€
   - Output: Contextualized answer based on retrieved news + filings.
   
---

## ğŸ“ Key Concepts Learned
- Retrieval-Augmented Generation (RAG) workflow
- Connecting **vector embeddings** with LLMs
- Combining multiple sources for context-aware responses
- Context concatenation and prompting for summarization

---

## ğŸ”® Next Step (Day 4)
We will enhance the RAG system by:
- Adding **semantic query answering with citations**
- Cleaning and formatting outputs
- Ensuring answers are **verifiable and reference their sources**


